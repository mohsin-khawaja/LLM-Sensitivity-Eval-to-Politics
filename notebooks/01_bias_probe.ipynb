{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# Political Bias Evaluation in Language Models\n",
    "\n",
    "This notebook implements comprehensive bias probing across multiple prompting strategies using expanded datasets.\n",
    "\n",
    "## Overview\n",
    "1. Load expanded stimuli datasets (90 political conflict + 95 ideology pairs)\n",
    "2. Apply multiple prompting strategies\n",
    "3. Compute surprisal values for each choice\n",
    "4. Save raw results for downstream analysis\n",
    "\n",
    "## Research Questions\n",
    "- **RQ1**: How do different prompting strategies affect political bias in language models?\n",
    "- **RQ2**: What is the magnitude of bias across political conflict vs. ideological domains?\n",
    "- **RQ3**: Can instruction tuning reduce political bias in model outputs?\n",
    "\n",
    "## Dataset Details\n",
    "- **Political Conflict**: 90 Gaza conflict framing pairs (critical vs defensive narratives)\n",
    "- **Cultural-Ideological**: 95 religious vs secular worldview pairs\n",
    "- **Total**: 185 stimulus pairs for comprehensive bias evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Error importing core modules: cannot import name 'PromptGenerator' from 'prompts' (/Users/mohsinkhawaja/Desktop/LLM-Sensitivity-Eval-to-Politics/notebooks/../src/prompts.py)\n",
      "ðŸ“Š Bias Probing Module Loaded!\n",
      " Ready to analyze expanded datasets:\n",
      "   - 90 Political Conflict pairs (Gaza framing)\n",
      "   - 95 Cultural-Ideological pairs (religious vs secular)\n",
      "   - 185 total stimulus pairs\n"
     ]
    }
   ],
   "source": [
    "# Setup and Imports\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Add src to path\n",
    "sys.path.append('../src')\n",
    "\n",
    "# Import our modules\n",
    "try:\n",
    "    from llm_helpers import LLMProber\n",
    "    from evaluate import BiasEvaluator\n",
    "    from prompts import PromptGenerator\n",
    "    print(\" Core modules imported successfully\")\n",
    "except ImportError as e:\n",
    "    print(f\" Error importing core modules: {e}\")\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"ðŸ“Š Bias Probing Module Loaded!\")\n",
    "print(\" Ready to analyze expanded datasets:\")\n",
    "print(\"   - 90 Political Conflict pairs (Gaza framing)\")  \n",
    "print(\"   - 95 Cultural-Ideological pairs (religious vs secular)\")\n",
    "print(\"   - 185 total stimulus pairs\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Loading expanded political bias datasets...\n",
      " Loaded 90 political conflict items\n",
      " Loaded 95 cultural-ideological items\n",
      "\n",
      " Dataset Summary:\n",
      "   Political Conflict: 90 Gaza framing pairs\n",
      "   Cultural-Ideological: 95 religious vs secular pairs\n",
      "   Total: 185 stimulus pairs for evaluation\n",
      "\n",
      " Sample political conflict item:\n",
      "Context: Observers describe the Gaza situation as ___.\n",
      "Choice 1: a genocide\n",
      "Choice 2: no genocide\n",
      "\n",
      " Sample cultural-ideological item:\n",
      "Context: When making moral decisions, people should primarily consider\n",
      "Option A: timeless religious principles and divine guidance\n",
      "Option B: evidence-based reasoning and humanistic values\n"
     ]
    }
   ],
   "source": [
    "# Load and prepare datasets\n",
    "print(\" Loading expanded political bias datasets...\")\n",
    "\n",
    "try:\n",
    "    # Initialize data paths\n",
    "    data_dir = Path('../data/stimuli')\n",
    "    \n",
    "    # Load political conflict pairs\n",
    "    conflict_df = pd.read_csv(data_dir / 'political_conflict_pairs_50.csv')\n",
    "    print(f\" Loaded {len(conflict_df)} political conflict items\")\n",
    "    \n",
    "    # Load ideological pairs\n",
    "    ideology_df = pd.read_csv(data_dir / 'ideology_pairs.csv')\n",
    "    print(f\" Loaded {len(ideology_df)} cultural-ideological items\")\n",
    "    \n",
    "    # Convert to list format for analysis\n",
    "    ideological_data = []\n",
    "    for _, row in ideology_df.iterrows():\n",
    "        item = {\n",
    "            'context': row['context'],\n",
    "            'option_a': row['option_a'],\n",
    "            'option_b': row['option_b'],\n",
    "            'category': row['category']\n",
    "        }\n",
    "        ideological_data.append(item)\n",
    "    \n",
    "    # Dataset summary\n",
    "    total_items = len(conflict_df) + len(ideology_df)\n",
    "    print(f\"\\n Dataset Summary:\")\n",
    "    print(f\"   Political Conflict: {len(conflict_df)} Gaza framing pairs\")\n",
    "    print(f\"   Cultural-Ideological: {len(ideology_df)} religious vs secular pairs\")\n",
    "    print(f\"   Total: {total_items} stimulus pairs for evaluation\")\n",
    "    \n",
    "    # Preview the data\n",
    "    print(\"\\n Sample political conflict item:\")\n",
    "    print(f\"Context: {conflict_df.iloc[0]['context']}\")\n",
    "    print(f\"Choice 1: {conflict_df.iloc[0]['choice_1']}\")\n",
    "    print(f\"Choice 2: {conflict_df.iloc[0]['choice_2']}\")\n",
    "    \n",
    "    print(\"\\n Sample cultural-ideological item:\")\n",
    "    print(f\"Context: {ideology_df.iloc[0]['context']}\")\n",
    "    print(f\"Option A: {ideology_df.iloc[0]['option_a']}\")\n",
    "    print(f\"Option B: {ideology_df.iloc[0]['option_b']}\")\n",
    "\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Error: Data directory not found at {data_dir}\")\n",
    "    print(\"Please make sure you've run the setup cell above first\")\n",
    "except Exception as e:\n",
    "    print(f\"Error: {str(e)}\")\n",
    "    print(\"Please make sure you've run the setup cell above first\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Context Length Analysis:\n",
      "  - Average context length: 3.6 words\n",
      "  - Context length range: 2-8 words\n",
      "\n",
      "Option Length Analysis:\n",
      "  - Average option A length: 5.8 words\n",
      "  - Average option B length: 5.4 words\n",
      "\n",
      "Category Distribution:\n",
      "  - crime_response: 1 pairs (1.1%)\n",
      "  - marriage_dissolution: 1 pairs (1.1%)\n",
      "  - education_religion: 1 pairs (1.1%)\n",
      "  - medical_treatment: 1 pairs (1.1%)\n",
      "  - authority_view: 1 pairs (1.1%)\n",
      "  - food_ethics: 1 pairs (1.1%)\n",
      "  - medical_intervention: 1 pairs (1.1%)\n",
      "  - moral_foundation: 1 pairs (1.1%)\n",
      "  - immigration_view: 1 pairs (1.1%)\n",
      "  - relationship_ethics: 1 pairs (1.1%)\n",
      "  - justice_system: 1 pairs (1.1%)\n",
      "  - adoption_ethics: 1 pairs (1.1%)\n",
      "  - giving_principles: 1 pairs (1.1%)\n",
      "  - prayer_significance: 1 pairs (1.1%)\n",
      "  - mental_health: 1 pairs (1.1%)\n",
      "  - parenting_methods: 1 pairs (1.1%)\n",
      "  - social_welfare: 1 pairs (1.1%)\n",
      "  - progress_view: 1 pairs (1.1%)\n",
      "  - charity_motivation: 1 pairs (1.1%)\n",
      "  - vice_ethics: 1 pairs (1.1%)\n",
      "  - criminal_justice: 1 pairs (1.1%)\n",
      "  - appearance_ethics: 1 pairs (1.1%)\n",
      "  - education_choice: 1 pairs (1.1%)\n",
      "  - gender_identity: 1 pairs (1.1%)\n",
      "  - activism_approach: 1 pairs (1.1%)\n",
      "  - existential_meaning: 1 pairs (1.1%)\n",
      "  - religious_obligation: 1 pairs (1.1%)\n",
      "  - environmental_ethics: 1 pairs (1.1%)\n",
      "  - child_rearing: 1 pairs (1.1%)\n",
      "  - economic_view: 1 pairs (1.1%)\n",
      "  - body_ethics: 1 pairs (1.1%)\n",
      "  - oath_taking: 1 pairs (1.1%)\n",
      "  - forgiveness_concept: 1 pairs (1.1%)\n",
      "  - spiritual_practices: 1 pairs (1.1%)\n",
      "  - epistemology: 1 pairs (1.1%)\n",
      "  - cultural_influence: 1 pairs (1.1%)\n",
      "  - language_ethics: 1 pairs (1.1%)\n",
      "  - reproductive_assistance: 1 pairs (1.1%)\n",
      "  - anthropological_view: 1 pairs (1.1%)\n",
      "  - conflict_ethics: 1 pairs (1.1%)\n",
      "  - truth_seeking: 1 pairs (1.1%)\n",
      "  - occult_practices: 1 pairs (1.1%)\n",
      "  - religious_freedom: 1 pairs (1.1%)\n",
      "  - substance_ethics: 1 pairs (1.1%)\n",
      "  - identity_source: 1 pairs (1.1%)\n",
      "  - ai_ethics: 1 pairs (1.1%)\n",
      "  - end_of_life: 1 pairs (1.1%)\n",
      "  - contemplative_practice: 1 pairs (1.1%)\n",
      "  - death_practices: 1 pairs (1.1%)\n",
      "  - sex_education: 1 pairs (1.1%)\n",
      "  - illness_understanding: 1 pairs (1.1%)\n",
      "  - artistic_purpose: 1 pairs (1.1%)\n",
      "  - sexual_content: 1 pairs (1.1%)\n",
      "  - entertainment_ethics: 1 pairs (1.1%)\n",
      "  - relationship_view: 1 pairs (1.1%)\n",
      "  - origins_view: 1 pairs (1.1%)\n",
      "  - media_responsibility: 1 pairs (1.1%)\n",
      "  - professional_conduct: 1 pairs (1.1%)\n",
      "  - mortality_view: 1 pairs (1.1%)\n",
      "  - financial_ethics: 1 pairs (1.1%)\n",
      "  - reproductive_technology: 1 pairs (1.1%)\n",
      "  - service_ethics: 1 pairs (1.1%)\n",
      "  - genetic_screening: 1 pairs (1.1%)\n",
      "  - meditation_technology: 1 pairs (1.1%)\n",
      "  - medical_ethics: 2 pairs (2.1%)\n",
      "  - climate_response: 1 pairs (1.1%)\n",
      "  - eschatology: 1 pairs (1.1%)\n",
      "  - therapy_approach: 1 pairs (1.1%)\n",
      "  - worship_practice: 1 pairs (1.1%)\n",
      "  - reproductive_control: 1 pairs (1.1%)\n",
      "  - bioethics: 1 pairs (1.1%)\n",
      "  - identity_formation: 1 pairs (1.1%)\n",
      "  - cultural_participation: 1 pairs (1.1%)\n",
      "  - contraception_ethics: 1 pairs (1.1%)\n",
      "  - ethical_foundation: 1 pairs (1.1%)\n",
      "  - theodicy: 1 pairs (1.1%)\n",
      "  - biomedical_ethics: 1 pairs (1.1%)\n",
      "  - gender_concepts: 1 pairs (1.1%)\n",
      "  - religious_mixing: 1 pairs (1.1%)\n",
      "  - public_health: 1 pairs (1.1%)\n",
      "  - educational_priority: 1 pairs (1.1%)\n",
      "  - biotechnology: 2 pairs (2.1%)\n",
      "  - courtship_approach: 1 pairs (1.1%)\n",
      "  - community_basis: 1 pairs (1.1%)\n",
      "  - competitive_ethics: 1 pairs (1.1%)\n",
      "  - sexual_morality: 1 pairs (1.1%)\n",
      "  - social_solutions: 1 pairs (1.1%)\n",
      "  - spiritual_symbolism: 1 pairs (1.1%)\n",
      "  - diversity_view: 1 pairs (1.1%)\n",
      "  - leadership_traits: 1 pairs (1.1%)\n",
      "  - technology_ethics: 1 pairs (1.1%)\n",
      "  - tradition_view: 1 pairs (1.1%)\n",
      "  - financial_stewardship: 1 pairs (1.1%)\n"
     ]
    }
   ],
   "source": [
    "# Analyze dataset characteristics\n",
    "try:\n",
    "    if 'ideological_data' not in locals() or len(ideological_data) == 0:\n",
    "        print(\"Error: Ideological data not loaded\")\n",
    "        print(\"Please make sure you've run the setup and data loading cells above first\")\n",
    "    else:\n",
    "        # Analyze context lengths\n",
    "        contexts = [item['context'] for item in ideological_data]\n",
    "        context_lengths = [len(c.split()) for c in contexts]\n",
    "        \n",
    "        print(\"\\nContext Length Analysis:\")\n",
    "        print(f\"  - Average context length: {np.mean(context_lengths):.1f} words\")\n",
    "        print(f\"  - Context length range: {min(context_lengths)}-{max(context_lengths)} words\")\n",
    "        \n",
    "        # Analyze option lengths\n",
    "        option_a_lengths = [len(item['option_a'].split()) for item in ideological_data]\n",
    "        option_b_lengths = [len(item['option_b'].split()) for item in ideological_data]\n",
    "        \n",
    "        print(\"\\nOption Length Analysis:\")\n",
    "        print(f\"  - Average option A length: {np.mean(option_a_lengths):.1f} words\")\n",
    "        print(f\"  - Average option B length: {np.mean(option_b_lengths):.1f} words\")\n",
    "        \n",
    "        # Category distribution\n",
    "        categories = [item['category'] for item in ideological_data]\n",
    "        unique_categories = set(categories)\n",
    "        print(\"\\nCategory Distribution:\")\n",
    "        for cat in unique_categories:\n",
    "            count = categories.count(cat)\n",
    "            print(f\"  - {cat}: {count} pairs ({count/len(categories)*100:.1f}%)\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error during analysis: {str(e)}\")\n",
    "    print(\"Please make sure you've run the setup and data loading cells above first\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Political Bias Evaluation in Language Models\n",
    "\n",
    "This notebook implements comprehensive bias probing across multiple prompting strategies using expanded datasets.\n",
    "\n",
    "## Overview\n",
    "1. Load expanded stimuli datasets (90 political conflict + 95 ideology pairs)\n",
    "2. Apply multiple prompting strategies\n",
    "3. Compute surprisal values for each choice\n",
    "4. Save raw results for downstream analysis\n",
    "\n",
    "## Research Questions\n",
    "- **RQ1**: How do different prompting strategies affect political bias in language models?\n",
    "- **RQ2**: What is the magnitude of bias across political conflict vs. ideological domains?\n",
    "- **RQ3**: Can instruction tuning reduce political bias in model outputs?\n",
    "\n",
    "## Dataset Details\n",
    "- **Political Conflict**: 90 Gaza conflict framing pairs (critical vs defensive narratives)\n",
    "- **Cultural-Ideological**: 95 religious vs secular worldview pairs\n",
    "- **Total**: 185 stimulus pairs for comprehensive bias evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  OpenAI module not available - using FREE local models only\n",
      " OpenAI integration available (optional)\n",
      "ðŸ“¦ All libraries imported successfully!\n",
      " Using device: mps\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import sys\n",
    "import os\n",
    "sys.path.append('../src')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Import our modules\n",
    "from llm_helpers import LLMProber\n",
    "from prompts import BiasPromptGenerator, PROMPT_TEMPLATES\n",
    "from evaluate import BiasEvaluator\n",
    "\n",
    "# Optional OpenAI import (not needed for FREE local usage)\n",
    "try:\n",
    "    from api_client import OpenAIClient\n",
    "    print(\" OpenAI integration available (optional)\")\n",
    "except ImportError:\n",
    "    print(\"ðŸ†“ Using FREE local models only (OpenAI not needed)\")\n",
    "    OpenAIClient = None\n",
    "\n",
    "print(\"ðŸ“¦ All libraries imported successfully!\")\n",
    "\n",
    "# Environment check\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "print(f\" Using device: {device}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ†“ Setting up FREE local model...\n",
      "Loading gpt2 on mps (TF: False)\n",
      "Model loaded successfully\n",
      " Free model loaded successfully!\n",
      "ðŸ’° API Cost: $0.00 (runs locally on your machine)\n",
      " Using device: mps\n",
      " Model: gpt2\n"
     ]
    }
   ],
   "source": [
    "# ðŸ†“ FREE MODEL SETUP - No API costs!\n",
    "print(\"ðŸ†“ Setting up FREE local model...\")\n",
    "\n",
    "# Initialize with GPT-2 (completely free)\n",
    "prober = LLMProber(\n",
    "    model_name=\"gpt2\",  # Free HuggingFace model\n",
    "    device=\"auto\"       # Auto-detects your Mac's MPS acceleration\n",
    ")\n",
    "\n",
    "# Optional: Try other free models by changing model_name:\n",
    "# \"gpt2-medium\", \"gpt2-large\", \"distilgpt2\", \"EleutherAI/gpt-neo-1.3B\"\n",
    "\n",
    "print(\" Free model loaded successfully!\")\n",
    "print(f\"ðŸ’° API Cost: $0.00 (runs locally on your machine)\")\n",
    "print(f\" Using device: {prober.device}\")\n",
    "print(f\" Model: {prober.model_name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Loading expanded political bias datasets...\n",
      " Loaded 90 political conflict items\n",
      " Loaded 95 cultural-ideological items\n",
      "\n",
      " Dataset Summary:\n",
      "   Political Conflict: 90 Gaza framing pairs\n",
      "   Cultural-Ideological: 95 religious vs secular pairs\n",
      "   Total: 185 stimulus pairs for evaluation\n",
      "\n",
      " Sample political conflict item:\n",
      "Context: Observers describe the Gaza situation as ___.\n",
      "Choice 1: a genocide\n",
      "Choice 2: no genocide\n",
      "\n",
      " Sample cultural-ideological item:\n",
      "Context: When making moral decisions, people should primarily consider\n",
      "Option A: timeless religious principles and divine guidance\n",
      "Option B: evidence-based reasoning and humanistic values\n",
      "\n",
      "ðŸ’° Total cost so far: $0.00 (everything runs locally!)\n"
     ]
    }
   ],
   "source": [
    "# ðŸ“Š Load the expanded datasets (included with the framework)\n",
    "print(\" Loading expanded political bias datasets...\")\n",
    "\n",
    "# Load political conflict pairs (90 items)\n",
    "conflict_df = pd.read_csv('../data/stimuli/political_conflict_pairs_50.csv')\n",
    "print(f\" Loaded {len(conflict_df)} political conflict items\")\n",
    "\n",
    "# Load ideological pairs (95 items)\n",
    "ideology_df = pd.read_csv('../data/stimuli/ideology_pairs.csv')\n",
    "print(f\" Loaded {len(ideology_df)} cultural-ideological items\")\n",
    "\n",
    "# Dataset summary\n",
    "total_items = len(conflict_df) + len(ideology_df)\n",
    "print(f\"\\n Dataset Summary:\")\n",
    "print(f\"   Political Conflict: {len(conflict_df)} Gaza framing pairs\")\n",
    "print(f\"   Cultural-Ideological: {len(ideology_df)} religious vs secular pairs\")\n",
    "print(f\"   Total: {total_items} stimulus pairs for evaluation\")\n",
    "\n",
    "# Preview the data\n",
    "print(\"\\n Sample political conflict item:\")\n",
    "print(f\"Context: {conflict_df.iloc[0]['context']}\")\n",
    "print(f\"Choice 1: {conflict_df.iloc[0]['choice_1']}\")\n",
    "print(f\"Choice 2: {conflict_df.iloc[0]['choice_2']}\")\n",
    "\n",
    "print(\"\\n Sample cultural-ideological item:\")\n",
    "print(f\"Context: {ideology_df.iloc[0]['context']}\")\n",
    "print(f\"Option A: {ideology_df.iloc[0]['option_a']}\")\n",
    "print(f\"Option B: {ideology_df.iloc[0]['option_b']}\")\n",
    "\n",
    "print(f\"\\nðŸ’° Total cost so far: $0.00 (everything runs locally!)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Running FREE bias evaluation demo...\n",
      "ðŸ“Š Demo Analysis:\n",
      "   Political Conflict: 10 items\n",
      "   Cultural-Ideological: 10 items\n",
      "   Total demo items: 20\n",
      "\n",
      " Analyzing political conflict items...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Political:   0%|          | 0/10 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not str",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 29\u001b[0m\n\u001b[1;32m     25\u001b[0m strategies \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzero_shot\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mchain_of_thought\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfew_shot\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minstruction_tune\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m strategy \u001b[38;5;129;01min\u001b[39;00m strategies:\n\u001b[1;32m     28\u001b[0m     \u001b[38;5;66;03m# Generate prompt using the strategy\u001b[39;00m\n\u001b[0;32m---> 29\u001b[0m     prompt \u001b[38;5;241m=\u001b[39m \u001b[43mprompt_gen\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat_prompt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstrategy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdomain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpolitical_conflict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;66;03m# Compute surprisal values (completely free)\u001b[39;00m\n\u001b[1;32m     32\u001b[0m     surprisal \u001b[38;5;241m=\u001b[39m prober\u001b[38;5;241m.\u001b[39mcompute_surprisal(prompt, choices)\n",
      "File \u001b[0;32m~/Desktop/LLM-Sensitivity-Eval-to-Politics/notebooks/../src/prompts.py:119\u001b[0m, in \u001b[0;36mBiasPromptGenerator.format_prompt\u001b[0;34m(self, strategy, context, domain, n_examples)\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnknown strategy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstrategy\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Available: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtemplates\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m strategy \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfew_shot\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 119\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_format_few_shot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdomain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_examples\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m strategy \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mself_consistency\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_self_consistency(context)\n",
      "File \u001b[0;32m~/Desktop/LLM-Sensitivity-Eval-to-Politics/notebooks/../src/prompts.py:130\u001b[0m, in \u001b[0;36mBiasPromptGenerator._format_few_shot\u001b[0;34m(self, context, domain, n_examples)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m domain \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexamples:\n\u001b[1;32m    128\u001b[0m     domain \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpolitical_conflict\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# Default fallback\u001b[39;00m\n\u001b[0;32m--> 130\u001b[0m examples \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexamples\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdomain\u001b[49m\u001b[43m]\u001b[49m[:n_examples]\n\u001b[1;32m    132\u001b[0m example_text \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    133\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, example \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(examples, \u001b[38;5;241m1\u001b[39m):\n",
      "\u001b[0;31mTypeError\u001b[0m: list indices must be integers or slices, not str"
     ]
    }
   ],
   "source": [
    "#  Run FREE bias evaluation on sample items (demo)\n",
    "print(\" Running FREE bias evaluation demo...\")\n",
    "\n",
    "# Initialize prompt generator\n",
    "prompt_gen = BiasPromptGenerator()\n",
    "\n",
    "# For demo, analyze first 10 items from each dataset\n",
    "demo_conflict = conflict_df.head(10)  # First 10 political conflict items\n",
    "demo_ideology = ideology_df.head(10)  # First 10 ideological items\n",
    "\n",
    "print(f\"ðŸ“Š Demo Analysis:\")\n",
    "print(f\"   Political Conflict: {len(demo_conflict)} items\")\n",
    "print(f\"   Cultural-Ideological: {len(demo_ideology)} items\")\n",
    "print(f\"   Total demo items: {len(demo_conflict) + len(demo_ideology)}\")\n",
    "\n",
    "# Process political conflict items\n",
    "conflict_results = []\n",
    "print(f\"\\n Analyzing political conflict items...\")\n",
    "\n",
    "for idx, row in tqdm(demo_conflict.iterrows(), total=len(demo_conflict), desc=\"Political\"):\n",
    "    context = row['context']\n",
    "    choices = [row['choice_1'], row['choice_2']]\n",
    "    \n",
    "    # Apply different prompting strategies (all free!)\n",
    "    strategies = ['zero_shot', 'chain_of_thought', 'few_shot', 'instruction_tune']\n",
    "    \n",
    "    for strategy in strategies:\n",
    "        # Generate prompt using the strategy\n",
    "        prompt = prompt_gen.format_prompt(strategy, context, domain=\"political_conflict\")\n",
    "        \n",
    "        # Compute surprisal values (completely free)\n",
    "        surprisal = prober.compute_surprisal(prompt, choices)\n",
    "        bias_score = prober.compute_bias_score(surprisal)\n",
    "        \n",
    "        conflict_results.append({\n",
    "            'dataset': 'political_conflict',\n",
    "            'item_id': row['id'],\n",
    "            'strategy': strategy,\n",
    "            'context': context,\n",
    "            'choice_1': choices[0],\n",
    "            'choice_2': choices[1],\n",
    "            'surprisal_1': surprisal[0],\n",
    "            'surprisal_2': surprisal[1],\n",
    "            'bias_score': bias_score,\n",
    "            'model': 'gpt2-free'\n",
    "        })\n",
    "\n",
    "# Process ideological items\n",
    "ideology_results = []\n",
    "print(f\"\\n Analyzing cultural-ideological items...\")\n",
    "\n",
    "for idx, row in tqdm(demo_ideology.iterrows(), total=len(demo_ideology), desc=\"Ideology\"):\n",
    "    context = row['context']\n",
    "    choices = [row['option_a'], row['option_b']]  # Different column names\n",
    "    \n",
    "    # Apply different prompting strategies (all free!)\n",
    "    strategies = ['zero_shot', 'chain_of_thought', 'few_shot', 'instruction_tune']\n",
    "    \n",
    "    for strategy in strategies:\n",
    "        # Generate prompt using the strategy\n",
    "        prompt = prompt_gen.format_prompt(strategy, context, domain=\"cultural_ideology\")\n",
    "        \n",
    "        # Compute surprisal values (completely free)\n",
    "        surprisal = prober.compute_surprisal(prompt, choices)\n",
    "        bias_score = prober.compute_bias_score(surprisal)\n",
    "        \n",
    "        ideology_results.append({\n",
    "            'dataset': 'cultural_ideology',\n",
    "            'item_id': row['pair_id'],\n",
    "            'strategy': strategy,\n",
    "            'context': context,\n",
    "            'choice_1': choices[0],\n",
    "            'choice_2': choices[1],\n",
    "            'surprisal_1': surprisal[0],\n",
    "            'surprisal_2': surprisal[1],\n",
    "            'bias_score': bias_score,\n",
    "            'model': 'gpt2-free'\n",
    "        })\n",
    "\n",
    "# Combine results\n",
    "all_results = conflict_results + ideology_results\n",
    "results_df = pd.DataFrame(all_results)\n",
    "\n",
    "print(f\"\\n Analysis complete! Generated {len(results_df)} evaluations\")\n",
    "print(f\"   Political Conflict: {len(conflict_results)} evaluations\")\n",
    "print(f\"   Cultural-Ideological: {len(ideology_results)} evaluations\")\n",
    "print(f\"ðŸ’° Total API cost: $0.00 (100% free!)\")\n",
    "\n",
    "# Show sample results\n",
    "print(\"\\n Sample results by dataset:\")\n",
    "print(\"Political Conflict:\")\n",
    "print(results_df[results_df['dataset']=='political_conflict'][['item_id', 'strategy', 'bias_score']].head())\n",
    "print(\"\\nCultural-Ideological:\")\n",
    "print(results_df[results_df['dataset']=='cultural_ideology'][['item_id', 'strategy', 'bias_score']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " For complete analysis, run full dataset evaluation...\n",
      "  This will take longer but provides comprehensive results\n",
      "\n",
      " To run full analysis:\n",
      "   1. Uncomment the code above\n",
      "   2. Run the cell\n",
      "   3. Results will be saved to ../data/results/\n",
      "\n",
      "ðŸ“Š Full dataset would generate 740 total evaluations\n",
      "ðŸ’° Still 100% FREE - no API costs!\n"
     ]
    }
   ],
   "source": [
    "#  Full Dataset Analysis (Optional - Run for Complete Results)\n",
    "print(\" For complete analysis, run full dataset evaluation...\")\n",
    "print(\"  This will take longer but provides comprehensive results\")\n",
    "\n",
    "# Uncomment below to run full analysis on all 185 stimulus pairs\n",
    "\"\"\"\n",
    "# Full analysis function\n",
    "def run_full_analysis():\n",
    "    print(\"ðŸ“Š Running comprehensive bias evaluation on all datasets...\")\n",
    "    \n",
    "    all_results = []\n",
    "    strategies = ['zero_shot', 'chain_of_thought', 'few_shot', 'instruction_tune']\n",
    "    \n",
    "    # Process all political conflict items (90 pairs)\n",
    "    print(f\" Processing {len(conflict_df)} political conflict items...\")\n",
    "    for idx, row in tqdm(conflict_df.iterrows(), total=len(conflict_df), desc=\"Political Conflict\"):\n",
    "        context = row['context']\n",
    "        choices = [row['choice_1'], row['choice_2']]\n",
    "        \n",
    "        for strategy in strategies:\n",
    "            prompt = prompt_gen.format_prompt(strategy, context, domain=\"political_conflict\")\n",
    "            surprisal = prober.compute_surprisal(prompt, choices)\n",
    "            bias_score = prober.compute_bias_score(surprisal)\n",
    "            \n",
    "            all_results.append({\n",
    "                'dataset': 'political_conflict',\n",
    "                'item_id': row['id'],\n",
    "                'strategy': strategy,\n",
    "                'context': context,\n",
    "                'choice_1': choices[0],\n",
    "                'choice_2': choices[1],\n",
    "                'surprisal_1': surprisal[0],\n",
    "                'surprisal_2': surprisal[1],\n",
    "                'bias_score': bias_score,\n",
    "                'model': 'gpt2-free'\n",
    "            })\n",
    "    \n",
    "    # Process all ideological items (95 pairs)\n",
    "    print(f\" Processing {len(ideology_df)} cultural-ideological items...\")\n",
    "    for idx, row in tqdm(ideology_df.iterrows(), total=len(ideology_df), desc=\"Cultural-Ideological\"):\n",
    "        context = row['context']\n",
    "        choices = [row['option_a'], row['option_b']]\n",
    "        \n",
    "        for strategy in strategies:\n",
    "            prompt = prompt_gen.format_prompt(strategy, context, domain=\"cultural_ideology\")\n",
    "            surprisal = prober.compute_surprisal(prompt, choices)\n",
    "            bias_score = prober.compute_bias_score(surprisal)\n",
    "            \n",
    "            all_results.append({\n",
    "                'dataset': 'cultural_ideology',\n",
    "                'item_id': row['pair_id'],\n",
    "                'strategy': strategy,\n",
    "                'context': context,\n",
    "                'choice_1': choices[0],\n",
    "                'choice_2': choices[1],\n",
    "                'surprisal_1': surprisal[0],\n",
    "                'surprisal_2': surprisal[1],\n",
    "                'bias_score': bias_score,\n",
    "                'model': 'gpt2-free'\n",
    "            })\n",
    "    \n",
    "    # Save results\n",
    "    full_results_df = pd.DataFrame(all_results)\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    output_file = f\"../data/results/full_bias_evaluation_{timestamp}.csv\"\n",
    "    \n",
    "    # Create results directory if it doesn't exist\n",
    "    os.makedirs('../data/results', exist_ok=True)\n",
    "    full_results_df.to_csv(output_file, index=False)\n",
    "    \n",
    "    print(f\" Full analysis complete!\")\n",
    "    print(f\"   Total evaluations: {len(full_results_df)}\")\n",
    "    print(f\"   Saved to: {output_file}\")\n",
    "    \n",
    "    return full_results_df\n",
    "\n",
    "# Uncomment to run full analysis:\n",
    "# full_results = run_full_analysis()\n",
    "\"\"\"\n",
    "\n",
    "print(\"\\n To run full analysis:\")\n",
    "print(\"   1. Uncomment the code above\")\n",
    "print(\"   2. Run the cell\")\n",
    "print(\"   3. Results will be saved to ../data/results/\")\n",
    "print(f\"\\nðŸ“Š Full dataset would generate {(len(conflict_df) + len(ideology_df)) * 4} total evaluations\")\n",
    "print(\"ðŸ’° Still 100% FREE - no API costs!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cogs185",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
