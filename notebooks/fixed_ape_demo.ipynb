{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# Fixed APE Integration Demo\n",
        "\n",
        "This notebook provides a working implementation of APE and advanced prompting techniques with proper error handling and data format management.\n",
        "\n",
        "## Features:\n",
        "- Proper data format handling for both datasets\n",
        "- Robust error handling for APE evaluation\n",
        "- Manual strategy comparison\n",
        "- Statistical validation\n",
        "- Results visualization\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Setup and Imports\n",
        "import sys\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from datetime import datetime\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "sys.path.append('../src')\n",
        "\n",
        "from llm_helpers import LLMProber\n",
        "from evaluate import BiasEvaluator\n",
        "from ape import AutomaticPromptEngineer\n",
        "from prompts import DIRECTIONAL_PROMPTS\n",
        "\n",
        "print(\"Fixed APE Integration Demo\")\n",
        "print(\"=\" * 30)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load datasets and initialize models\n",
        "print(\"Loading datasets...\")\n",
        "political_df = pd.read_csv('../data/stimuli/political_conflict_pairs_50.csv')\n",
        "ideology_df = pd.read_csv('../data/stimuli/ideology_pairs.csv')\n",
        "\n",
        "print(f\"Political dataset: {len(political_df)} pairs\")\n",
        "print(f\"Ideology dataset: {len(ideology_df)} pairs\")\n",
        "\n",
        "# Initialize models\n",
        "print(\"\\nInitializing models...\")\n",
        "prober = LLMProber(\"gpt2\", device=\"auto\")\n",
        "evaluator = BiasEvaluator()\n",
        "ape_engine = AutomaticPromptEngineer(prober, evaluator)\n",
        "\n",
        "print(\"Models initialized successfully!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Prepare unified dataset in correct format\n",
        "def prepare_unified_stimuli():\n",
        "    \"\"\"Convert both datasets to unified format for APE.\"\"\"\n",
        "    unified_stimuli = []\n",
        "    \n",
        "    # Process political conflict data\n",
        "    print(\"Processing political conflict data...\")\n",
        "    for _, row in political_df.head(8).iterrows():  # Use smaller sample for demo\n",
        "        stimulus = {\n",
        "            'id': f\"political_{row['id']}\",\n",
        "            'dataset': 'political_conflict',\n",
        "            'context': row['context'],\n",
        "            'option_a': row['choice_1'],  # Pro-Palestinian framing\n",
        "            'option_b': row['choice_2'],  # Pro-Israeli framing\n",
        "            'category': 'Gaza_conflict'\n",
        "        }\n",
        "        unified_stimuli.append(stimulus)\n",
        "    \n",
        "    # Process cultural-ideological data\n",
        "    print(\"Processing cultural-ideological data...\")\n",
        "    for _, row in ideology_df.head(8).iterrows():  # Use smaller sample for demo\n",
        "        stimulus = {\n",
        "            'id': f\"ideology_{row['pair_id']}\",\n",
        "            'dataset': 'cultural_ideological',\n",
        "            'context': row['context'],\n",
        "            'option_a': row['option_a'],  # Religious framing\n",
        "            'option_b': row['option_b'],  # Secular framing\n",
        "            'category': row['category']\n",
        "        }\n",
        "        unified_stimuli.append(stimulus)\n",
        "    \n",
        "    return unified_stimuli\n",
        "\n",
        "# Create unified dataset\n",
        "unified_stimuli = prepare_unified_stimuli()\n",
        "print(f\"\\nCreated unified dataset with {len(unified_stimuli)} stimuli\")\n",
        "\n",
        "# Show samples\n",
        "print(\"\\nSample political stimulus:\")\n",
        "pol_sample = [s for s in unified_stimuli if s['dataset'] == 'political_conflict'][0]\n",
        "print(f\"Context: {pol_sample['context']}\")\n",
        "print(f\"Option A: {pol_sample['option_a']}\")\n",
        "print(f\"Option B: {pol_sample['option_b']}\")\n",
        "\n",
        "print(\"\\nSample ideological stimulus:\")\n",
        "ideo_sample = [s for s in unified_stimuli if s['dataset'] == 'cultural_ideological'][0]\n",
        "print(f\"Context: {ideo_sample['context']}\")\n",
        "print(f\"Option A: {ideo_sample['option_a']}\")\n",
        "print(f\"Option B: {ideo_sample['option_b']}\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
