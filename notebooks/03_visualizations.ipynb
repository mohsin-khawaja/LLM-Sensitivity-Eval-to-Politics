{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# Advanced Visualizations and Comparative Analysis\n",
        "\n",
        "This notebook creates comprehensive visualizations of bias evaluation results including bar charts, scatter plots, heatmaps, and comparative analyses.\n",
        "\n",
        "## Overview\n",
        "\n",
        "Advanced visualization techniques for bias analysis:\n",
        "\n",
        "- **Bias distribution plots** across categories and strategies\n",
        "- **Heatmaps** showing bias patterns\n",
        "- **Scatter plots** for correlation analysis  \n",
        "- **Bar charts** for comparative results\n",
        "- **Interactive plots** for exploration\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "ename": "ImportError",
          "evalue": "cannot import name 'load_experimental_data' from 'evaluate' (/Users/mohsinkhawaja/Desktop/LLM-Sensitivity-Eval-to-Politics/notebooks/../src/evaluate.py)",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[9], line 15\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Add src to path\u001b[39;00m\n\u001b[1;32m     13\u001b[0m sys\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../src\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mevaluate\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m load_experimental_data, comprehensive_bias_analysis\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# Set style\u001b[39;00m\n\u001b[1;32m     18\u001b[0m plt\u001b[38;5;241m.\u001b[39mstyle\u001b[38;5;241m.\u001b[39muse(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mseaborn-v0_8\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
            "\u001b[0;31mImportError\u001b[0m: cannot import name 'load_experimental_data' from 'evaluate' (/Users/mohsinkhawaja/Desktop/LLM-Sensitivity-Eval-to-Politics/notebooks/../src/evaluate.py)"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "from pathlib import Path\n",
        "\n",
        "# Simple, reliable data loading function\n",
        "def load_experimental_data(results_dir='../data/results'):\n",
        "    \"\"\"Load the most recent experimental results CSV file.\"\"\"\n",
        "    results_path = Path(results_dir)\n",
        "    if not results_path.exists():\n",
        "        print(f\"‚ö†Ô∏è  Results directory not found: {results_path}\")\n",
        "        return None\n",
        "    \n",
        "    csv_files = list(results_path.glob('*.csv'))\n",
        "    if not csv_files:\n",
        "        print(f\"‚ö†Ô∏è  No CSV files found in {results_path}\")\n",
        "        return None\n",
        "    \n",
        "    # Load the most recent file\n",
        "    latest_file = max(csv_files, key=lambda x: x.stat().st_mtime)\n",
        "    \n",
        "    try:\n",
        "        df = pd.read_csv(latest_file)\n",
        "        print(f\"‚úÖ Loaded experimental data: {latest_file.name}\")\n",
        "        print(f\"   Shape: {df.shape}\")\n",
        "        \n",
        "        # Show column info\n",
        "        if not df.empty:\n",
        "            print(f\"   Columns: {list(df.columns)}\")\n",
        "            if 'strategy' in df.columns:\n",
        "                print(f\"   Strategies: {df['strategy'].value_counts().to_dict()}\")\n",
        "            if 'dataset' in df.columns:\n",
        "                print(f\"   Datasets: {df['dataset'].value_counts().to_dict()}\")\n",
        "        \n",
        "        return df\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error loading {latest_file}: {e}\")\n",
        "        return None\n",
        "\n",
        "# Simple bias analysis function\n",
        "def simple_bias_analysis(results_df):\n",
        "    \"\"\"Perform basic bias analysis on results DataFrame.\"\"\"\n",
        "    if results_df is None or results_df.empty:\n",
        "        return None\n",
        "    \n",
        "    analysis = {\n",
        "        'summary_stats': {\n",
        "            'total_evaluations': len(results_df),\n",
        "            'mean_bias': results_df['bias_score'].mean(),\n",
        "            'std_bias': results_df['bias_score'].std(),\n",
        "            'median_bias': results_df['bias_score'].median(),\n",
        "            'min_bias': results_df['bias_score'].min(),\n",
        "            'max_bias': results_df['bias_score'].max()\n",
        "        }\n",
        "    }\n",
        "    \n",
        "    # Analysis by strategy\n",
        "    if 'strategy' in results_df.columns:\n",
        "        analysis['by_strategy'] = {}\n",
        "        for strategy in results_df['strategy'].unique():\n",
        "            strategy_data = results_df[results_df['strategy'] == strategy]\n",
        "            bias_scores = strategy_data['bias_score'].tolist()\n",
        "            \n",
        "            analysis['by_strategy'][strategy] = {\n",
        "                'mean_bias': np.mean(bias_scores),\n",
        "                'std_bias': np.std(bias_scores),\n",
        "                'n_examples': len(bias_scores)\n",
        "            }\n",
        "    \n",
        "    # Analysis by dataset\n",
        "    if 'dataset' in results_df.columns:\n",
        "        analysis['by_dataset'] = {}\n",
        "        for dataset in results_df['dataset'].unique():\n",
        "            dataset_data = results_df[results_df['dataset'] == dataset]\n",
        "            bias_scores = dataset_data['bias_score'].tolist()\n",
        "            \n",
        "            analysis['by_dataset'][dataset] = {\n",
        "                'mean_bias': np.mean(bias_scores),\n",
        "                'std_bias': np.std(bias_scores),\n",
        "                'n_examples': len(bias_scores)\n",
        "            }\n",
        "    \n",
        "    return analysis\n",
        "\n",
        "# Set style\n",
        "plt.style.use('seaborn-v0_8')\n",
        "sns.set_palette(\"husl\")\n",
        "plt.rcParams['figure.figsize'] = (12, 8)\n",
        "\n",
        "print(\"üé® Visualization Module Loaded!\")\n",
        "print(\"üìä Ready to create advanced plots for expanded datasets\")\n",
        "print(\"üîß Using standalone functions to avoid import issues\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üìÇ Loading expanded datasets for visualization...\n",
            "‚úÖ Stimulus datasets loaded:\n",
            "   Political Conflict: 90 Gaza framing pairs\n",
            "   Cultural-Ideological: 95 religious vs secular pairs\n",
            "   Total: 185 stimulus pairs\n",
            "\n",
            "‚ö†Ô∏è  Could not load results: name 'load_experimental_data' is not defined\n",
            "   Run notebook 01_bias_probe.ipynb to generate data first.\n"
          ]
        }
      ],
      "source": [
        "# üìä Load Expanded Datasets and Results\n",
        "print(\"üìÇ Loading expanded datasets for visualization...\")\n",
        "\n",
        "# Load stimulus datasets\n",
        "conflict_df = pd.read_csv('../data/stimuli/political_conflict_pairs_50.csv')\n",
        "ideology_df = pd.read_csv('../data/stimuli/ideology_pairs.csv')\n",
        "\n",
        "print(f\"‚úÖ Stimulus datasets loaded:\")\n",
        "print(f\"   Political Conflict: {len(conflict_df)} Gaza framing pairs\")\n",
        "print(f\"   Cultural-Ideological: {len(ideology_df)} religious vs secular pairs\")\n",
        "print(f\"   Total: {len(conflict_df) + len(ideology_df)} stimulus pairs\")\n",
        "\n",
        "# Try to load experimental results\n",
        "results_df = None\n",
        "try:\n",
        "    results_df = load_experimental_data()\n",
        "    if results_df is not None:\n",
        "        print(f\"\\nüìà Results loaded successfully:\")\n",
        "        print(f\"   Total evaluations: {len(results_df)}\")\n",
        "        \n",
        "        # Dataset breakdown\n",
        "        if 'dataset' in results_df.columns:\n",
        "            dataset_counts = results_df['dataset'].value_counts()\n",
        "            print(f\"   By dataset: {dataset_counts.to_dict()}\")\n",
        "            \n",
        "        # Strategy breakdown  \n",
        "        if 'strategy' in results_df.columns:\n",
        "            strategy_counts = results_df['strategy'].value_counts()\n",
        "            print(f\"   By strategy: {strategy_counts.to_dict()}\")\n",
        "            \n",
        "        print(\"üé® Ready for advanced visualizations!\")\n",
        "    else:\n",
        "        print(f\"\\n‚ö†Ô∏è  No experimental results found.\")\n",
        "        print(\"   Run notebook 01_bias_probe.ipynb to generate data first.\")\n",
        "        \n",
        "except Exception as e:\n",
        "    print(f\"\\n‚ö†Ô∏è  Could not load results: {e}\")\n",
        "    print(\"   Run notebook 01_bias_probe.ipynb to generate data first.\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "cogs185",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.21"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
