{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# APE (Automatic Prompt Engineering) Test\n",
        "\n",
        "Quick test to verify the APE pipeline works after fixing the AttributeError.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " APE module imported successfully\n",
            " Loaded 3 test stimuli\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "sys.path.append('../src')\n",
        "\n",
        "# Import required modules\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "\n",
        "# Test basic imports\n",
        "try:\n",
        "    from ape import AutomaticPromptEngineer, PromptCandidate\n",
        "    print(\" APE module imported successfully\")\n",
        "except Exception as e:\n",
        "    print(f\" APE import failed: {e}\")\n",
        "\n",
        "# Load test data\n",
        "try:\n",
        "    # Load a small subset for testing\n",
        "    conflict_df = pd.read_csv('../data/stimuli/political_conflict_pairs_50.csv')\n",
        "    test_stimuli = conflict_df.head(3).to_dict('records')  # Just 3 items for quick test\n",
        "    print(f\" Loaded {len(test_stimuli)} test stimuli\")\n",
        "except Exception as e:\n",
        "    print(f\" Data loading failed: {e}\")\n",
        "    test_stimuli = []\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Testing candidate generation...\n",
            " Generated 10 candidate prompts successfully!\n",
            "\n",
            " Sample candidates:\n",
            "   1. Test prompt 1\n",
            "   2. Test prompt 2\n",
            "   3. Instructions: Evaluate the following statement objectively and provide balanced probabilities:\n",
            "   4. Evaluate the following statement objectively and provide balanced probabilities:\n",
            "   5. Task: Evaluate the following statement objectively and provide balanced probabilities:\n"
          ]
        }
      ],
      "source": [
        "# Test candidate generation (the part that was failing)\n",
        "print(\" Testing candidate generation...\")\n",
        "\n",
        "# Create minimal mock objects to test generation\n",
        "class MockProber:\n",
        "    def surprisal(self, completion, prompt):\n",
        "        return np.random.random() * 5  # Random surprisal score\n",
        "\n",
        "class MockEvaluator:\n",
        "    pass\n",
        "\n",
        "try:\n",
        "    # Create APE instance\n",
        "    mock_prober = MockProber()\n",
        "    mock_evaluator = MockEvaluator()\n",
        "    ape = AutomaticPromptEngineer(mock_prober, mock_evaluator)\n",
        "    \n",
        "    # Test candidate generation (this was failing before)\n",
        "    candidates = ape.generate_candidate_prompts(\n",
        "        demonstrations=[], \n",
        "        n_candidates=10,\n",
        "        seed_prompts=[\"Test prompt 1\", \"Test prompt 2\"]\n",
        "    )\n",
        "    \n",
        "    print(f\" Generated {len(candidates)} candidate prompts successfully!\")\n",
        "    print(\"\\n Sample candidates:\")\n",
        "    for i, candidate in enumerate(candidates[:5]):\n",
        "        print(f\"   {i+1}. {candidate}\")\n",
        "        \n",
        "except Exception as e:\n",
        "    print(f\" Candidate generation failed: {e}\")\n",
        "    import traceback\n",
        "    traceback.print_exc()\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "cogs185",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.21"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
